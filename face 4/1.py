




















# import cv2
# import os
# import json

# # --- Náº¡p mÃ´ hÃ¬nh deep learning cá»§a OpenCV ---
# configFile = "deploy.prototxt.txt"
# modelFile  = "res10_300x300_ssd_iter_140000.caffemodel"
# DATASET_DIR = 'dataset'
# INFO_FILE = 'thong tin cac lop.txt'

# # Táº¡o thÆ° má»¥c dataset náº¿u chÆ°a cÃ³
# os.makedirs(DATASET_DIR, exist_ok=True)

# # Náº¡p model
# net = cv2.dnn.readNetFromCaffe(configFile, modelFile)

# # --- Há»i thÃ´ng tin sinh viÃªn ---
# lop = input("Nháº­p tÃªn lá»›p há»c: ").strip()
# face_id = input("Nháº­p ID sinh viÃªn: ").strip()
# name = input("Nháº­p tÃªn sinh viÃªn: ").strip()

# # --- Äáº£m báº£o lá»›p tá»“n táº¡i ---
# lop_dir = os.path.join(DATASET_DIR, lop)
# os.makedirs(lop_dir, exist_ok=True)

# # --- Cáº­p nháº­t file JSON ---
# if os.path.exists(INFO_FILE):
#     try:
#         with open(INFO_FILE, "r", encoding="utf-8") as f:
#             classes_info = json.load(f)
#     except json.JSONDecodeError:
#         classes_info = {}
# else:
#     classes_info = {}

# if lop not in classes_info:
#     classes_info[lop] = {}

# classes_info[lop][face_id] = name

# # --- Ghi láº¡i file ---
# with open(INFO_FILE, "w", encoding="utf-8") as f:
#     json.dump(classes_info, f, ensure_ascii=False, indent=4)

# print(f"âœ… ÄÃ£ cáº­p nháº­t sinh viÃªn {name} (ID: {face_id}) vÃ o lá»›p {lop}")

# # --- Báº¯t Ä‘áº§u thu tháº­p áº£nh ---
# count = 0
# MAX_COUNT = 200
# cam = cv2.VideoCapture(0, cv2.CAP_DSHOW)

# print("ğŸ“· Báº¯t Ä‘áº§u chá»¥p áº£nh khuÃ´n máº·t... (Nháº¥n 'q' Ä‘á»ƒ thoÃ¡t)")

# while True:
#     ret, frame = cam.read()
#     if not ret:
#         break

#     frame = cv2.flip(frame, 1)
#     h, w = frame.shape[:2]

#     blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0,
#                                  (300, 300), (104.0, 177.0, 123.0))
#     net.setInput(blob)
#     detections = net.forward()

#     for i in range(detections.shape[2]):
#         confidence = detections[0, 0, i, 2]
#         if confidence > 0.6:
#             box = detections[0, 0, i, 3:7] * [w, h, w, h]
#             (x1, y1, x2, y2) = box.astype("int")

#             face = frame[y1:y2, x1:x2]
#             if face.size > 0 and count < MAX_COUNT:
#                 count += 1
#                 save_path = os.path.join(lop_dir, f"User.{face_id}.{count}.jpg")
#                 cv2.imwrite(save_path, face)

#                 cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
#                 cv2.putText(frame, f"Saved: {count}", (x1, y1 - 10),
#                             cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

#     cv2.imshow("Face Capture", frame)

#     if cv2.waitKey(1) & 0xFF == ord('q') or count >= MAX_COUNT:
#         break

# cam.release()
# cv2.destroyAllWindows()
# print(f"ğŸ“ ÄÃ£ lÆ°u {count} áº£nh vÃ o {lop_dir}")






















import time
import cv2
import os
import json

# --- Náº¡p mÃ´ hÃ¬nh deep learning cá»§a OpenCV ---
configFile = "deploy.prototxt.txt"
modelFile  = "res10_300x300_ssd_iter_140000.caffemodel"
DATASET_DIR = 'dataset'
INFO_FILE = 'thong tin cac lop.txt'

# Táº¡o thÆ° má»¥c dataset náº¿u chÆ°a cÃ³
os.makedirs(DATASET_DIR, exist_ok=True)

# Náº¡p model
net = cv2.dnn.readNetFromCaffe(configFile, modelFile)

# --- Há»i thÃ´ng tin sinh viÃªn ---
lop = input("Nháº­p tÃªn lá»›p há»c: ").strip()
face_id = input("Nháº­p ID sinh viÃªn: ").strip()
name = input("Nháº­p tÃªn sinh viÃªn: ").strip()

# --- Äáº£m báº£o lá»›p tá»“n táº¡i ---
lop_dir = os.path.join(DATASET_DIR, lop)
os.makedirs(lop_dir, exist_ok=True)

# --- Cáº­p nháº­t file JSON ---
if os.path.exists(INFO_FILE):
    try:
        with open(INFO_FILE, "r", encoding="utf-8") as f:
            classes_info = json.load(f)
    except json.JSONDecodeError:
        classes_info = {}
else:
    classes_info = {}

if lop not in classes_info:
    classes_info[lop] = {}

classes_info[lop][face_id] = name

# --- Ghi láº¡i file ---
with open(INFO_FILE, "w", encoding="utf-8") as f:
    json.dump(classes_info, f, ensure_ascii=False, indent=4)

print(f"âœ… ÄÃ£ cáº­p nháº­t sinh viÃªn {name} (ID: {face_id}) vÃ o lá»›p {lop}")

# --- Báº¯t Ä‘áº§u thu tháº­p áº£nh ---
count = 0
MAX_COUNT = 200
cam = cv2.VideoCapture(0, cv2.CAP_DSHOW)
prev_time = time.time()
fps = 0
print("ğŸ“· Báº¯t Ä‘áº§u chá»¥p áº£nh khuÃ´n máº·t... (Nháº¥n 'q' Ä‘á»ƒ thoÃ¡t)")

while True:
    ret, frame = cam.read()
    if not ret:
        break

    frame = cv2.flip(frame, 0)
    h, w = frame.shape[:2]
    current_time = time.time()
    fps = 1 / (current_time - prev_time)
    prev_time = current_time

    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0,
                                 (300, 300), (104.0, 177.0, 123.0))
    net.setInput(blob)
    detections = net.forward()

    for i in range(detections.shape[2]):
        confidence = detections[0, 0, i, 2]
        if confidence > 0.6:
            box = detections[0, 0, i, 3:7] * [w, h, w, h]
            (x1, y1, x2, y2) = box.astype("int")

            face = frame[y1:y2, x1:x2]
            if face.size > 0 and count < MAX_COUNT:
                count += 1
                save_path = os.path.join(lop_dir, f"User.{face_id}.{count}.jpg")
                cv2.imwrite(save_path, face)

                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                cv2.putText(frame, f"Saved: {count}", (x1, y1 - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
    cv2.putText(frame,
            f"FPS: {int(fps)}",
            (10, 30),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.8,
            (0, 0, 255),
            2)

    cv2.imshow("Face Capture", frame)

    if cv2.waitKey(1) & 0xFF == ord('q') or count >= MAX_COUNT:
        break

cam.release()
cv2.destroyAllWindows()
print(f"ğŸ“ ÄÃ£ lÆ°u {count} áº£nh vÃ o {lop_dir}")


